{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "A well chosen initialization can:\n",
    "- Speed up the convergence of gradient descent\n",
    "- Increase the odds of gradient descent converging to a lower training (and generalization) error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from init_utils import sigmoid, relu, compute_loss, forward_propagation, backward_propagation, update_parameters, predict, predict_dec, load_dataset, plot_decision_boundary\n",
    "\n",
    "# Some defaults for this notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (7.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets for blue/red dots in circle\n",
    "train_X, train_Y, test_X, test_Y = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are three ways to initialize the parameters\n",
    "    1.) Initialize with zeros\n",
    "    2.) Initialize with randam values\n",
    "    3.) He Initialization -> This initializes the weights to random values scaled according to a paper by He et al., 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.) Initialize with Zeros\n",
    "def initialize_parameters_zeros(layers_dims):\n",
    "    params = {}\n",
    "    L = len(layers_dims)\n",
    "    for l in range(1, L):\n",
    "        params['W' + str(l)] = np.zeros((layers_dims[l], layers_dims[l-1]))\n",
    "        params['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initialize_parameters_zeros([4,3,2,1])\n",
    "print('Zero Initialization : ', (params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.) Random Initialization\n",
    "def initialize_parameters_random(layers_dims):\n",
    "    np.random.seed(3)\n",
    "    params = {}\n",
    "    L = len(layers_dims)\n",
    "    for l in range(1, L):\n",
    "        params['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * 10\n",
    "        params['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initialize_parameters_random([3,2,1])\n",
    "print('Random Initialization : ', (params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.) He Initialization\n",
    "def initialize_parameters_he(layers_dims):\n",
    "    import math\n",
    "\n",
    "    np.random.seed(3)\n",
    "    params = {}\n",
    "    L = len(layers_dims) - 1\n",
    "    for l in range(1, L+1):\n",
    "        params['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * math.sqrt(2./layers_dims[l-1])\n",
    "        params['b' + str(l)] = np.zeros((layers_dims[l], 1)) * math.sqrt(2./layers_dims[l-1])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initialize_parameters_he([2, 4,1])\n",
    "print('He Initialization : ', (params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need NN model to test all these 3 initialization methods\n",
    "def NN_model(X, Y, lr = 0.01, n_iter = 10000, pc = False, init = 'zeros'):\n",
    "    grads = {}\n",
    "    costs = []\n",
    "    m = X.shape[1]\n",
    "    layers_dims = [X.shape[0], 10, 5, 1]\n",
    "\n",
    "    # Initialization\n",
    "    if init == 'zeros':\n",
    "        params = initialize_parameters_zeros(layers_dims)\n",
    "    elif init == 'random':\n",
    "        params = initialize_parameters_random(layers_dims)\n",
    "    elif init == 'he':\n",
    "        params = initialize_parameters_he(layers_dims)\n",
    "    \n",
    "    # Loop for gradient descent\n",
    "    for i in range(0, n_iter):\n",
    "        a3, cache = forward_propagation(X, params)\n",
    "        cost = compute_loss(a3, Y)\n",
    "        grads = backward_propagation(X, Y, cache)\n",
    "        params = update_parameters(params, grads, lr)\n",
    "\n",
    "        # Print Cost every 1000 iterations\n",
    "        if pc and i % 1000 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
    "            costs.append(cost)\n",
    "    # Plot the loss\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations per hundreds')\n",
    "    plt.title(\"Learning rate =\" + str(lr))\n",
    "    plt.show()\n",
    "    \n",
    "    return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Zero Initialization\n",
    "params = NN_model(train_X, train_Y, lr = 0.01, n_iter = 15000, pc = True, init = \"zeros\")\n",
    "print (\"On the train set:\")\n",
    "predictions_train = predict(train_X, train_Y, params)\n",
    "print (\"On the test set:\")\n",
    "predictions_test = predict(test_X, test_Y, params)\n",
    "\n",
    "plt.title(\"Model with Zeros initialization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,1.5])\n",
    "axes.set_ylim([-1.5,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(params, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Random Initialization\n",
    "params = NN_model(train_X, train_Y, lr = 0.01, n_iter = 15000, pc = True, init = \"random\")\n",
    "print (\"On the train set:\")\n",
    "predictions_train = predict(train_X, train_Y, params)\n",
    "print (\"On the test set:\")\n",
    "predictions_test = predict(test_X, test_Y, params)\n",
    "\n",
    "plt.title(\"Model with Random initialization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,1.5])\n",
    "axes.set_ylim([-1.5,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(params, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For He Initialization\n",
    "params = NN_model(train_X, train_Y, lr = 0.01, n_iter = 15000, pc = True, init = \"he\")\n",
    "print (\"On the train set:\")\n",
    "predictions_train = predict(train_X, train_Y, params)\n",
    "print (\"On the test set:\")\n",
    "predictions_test = predict(test_X, test_Y, params)\n",
    "\n",
    "plt.title(\"Model with He initialization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,1.5])\n",
    "axes.set_ylim([-1.5,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(params, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "You have seen three different types of initializations. For the same number of iterations and same hyperparameters the comparison is:\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td>\n",
    "        Model\n",
    "        </td>\n",
    "        <td>\n",
    "        Train accuracy\n",
    "        </td>\n",
    "        <td>\n",
    "        Problem/Comment\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            with zeros initialization\n",
    "        </td>\n",
    "        <td>\n",
    "            50%\n",
    "        </td>\n",
    "        <td>\n",
    "            fails to break symmetry\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        3-layer NN with large random initialization\n",
    "        </td>\n",
    "        <td>\n",
    "        83%\n",
    "        </td>\n",
    "        <td>\n",
    "        too large weights \n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        3-layer NN with He initialization\n",
    "        </td>\n",
    "        <td>\n",
    "        99%\n",
    "        </td>\n",
    "        <td>\n",
    "        recommended method\n",
    "        </td>\n",
    "    </tr>\n",
    "</table> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
